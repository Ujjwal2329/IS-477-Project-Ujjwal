{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92c9ea63",
   "metadata": {},
   "source": [
    "# 03 – Data Quality Assessment and Cleaning\n",
    "\n",
    "This notebook documents the **data quality** and **cleaning** steps for the\n",
    "project. It complements the script `scripts/clean_data.py` and provides\n",
    "exploratory checks and summaries.\n",
    "\n",
    "Goals:\n",
    "\n",
    "- Profile the cleaned datasets:\n",
    "  - `coffee_sales_clean.csv`\n",
    "  - `coffee_shop_clean.csv`\n",
    "- Assess data quality:\n",
    "  - Missing values\n",
    "  - Potential outliers\n",
    "  - Duplicate records\n",
    "- Describe and justify key cleaning decisions:\n",
    "  - Dropping invalid or missing quantities/prices\n",
    "  - Cleaning `hour_of_day` and `money` in the shop data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b727c9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "\n",
    "SALES_CLEAN = PROCESSED_DIR / \"coffee_sales_clean.csv\"\n",
    "SHOP_CLEAN = PROCESSED_DIR / \"coffee_shop_clean.csv\"\n",
    "\n",
    "PROJECT_ROOT, DATA_DIR, PROCESSED_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3874a438",
   "metadata": {},
   "source": [
    "## 1. (Optional) Regenerate cleaned data\n",
    "\n",
    "If you have updated `scripts/clean_data.py`, you can re-run it here to\n",
    "regenerate the cleaned CSV files.\n",
    "\n",
    "Otherwise, you can skip this cell and use the existing cleaned files in\n",
    "`data/processed/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa5f2bd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: Uncomment to regenerate cleaned data\n",
    "# !python ../scripts/clean_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa30e8",
   "metadata": {},
   "source": [
    "## 2. Load cleaned datasets\n",
    "\n",
    "We now load:\n",
    "\n",
    "- `data/processed/coffee_sales_clean.csv`\n",
    "- `data/processed/coffee_shop_clean.csv`\n",
    "\n",
    "These should reflect the cleaning rules in `scripts/clean_data.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea599ce0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv(SALES_CLEAN)\n",
    "shop = pd.read_csv(SHOP_CLEAN)\n",
    "\n",
    "print(\"Sales (clean) shape:\", sales.shape)\n",
    "print(\"Shop  (clean) shape:\", shop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a695153",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6cca6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "shop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e867e1a",
   "metadata": {},
   "source": [
    "## 3. Schema and missing values\n",
    "\n",
    "We inspect:\n",
    "\n",
    "- Column names and data types (`info()`).\n",
    "- Missing values per column (`isna().sum()`).\n",
    "\n",
    "This helps verify that critical fields (e.g., `transaction_qty`,\n",
    "`unit_price`, `hour_of_day`, `money`) have been cleaned appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbb264",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== Sales info ===\")\n",
    "print(sales.info())\n",
    "\n",
    "print(\"\\n=== Missing values in sales ===\")\n",
    "print(sales.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89acc737",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== Shop info ===\")\n",
    "print(shop.info())\n",
    "\n",
    "print(\"\\n=== Missing values in shop ===\")\n",
    "print(shop.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111c1217",
   "metadata": {},
   "source": [
    "## 4. Duplicate checks\n",
    "\n",
    "We verify that there are no unexpected duplicate rows, especially on\n",
    "key identifiers:\n",
    "\n",
    "- `transaction_id` in the sales data.\n",
    "- (`hour_of_day`, `coffee_name`) or just `hour_of_day` in the shop data,\n",
    "  depending on how the dataset is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e8cbb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Sales duplicates by transaction_id\n",
    "if \"transaction_id\" in sales.columns:\n",
    "    dup_sales = sales.duplicated(subset=[\"transaction_id\"]).sum()\n",
    "    print(f\"Duplicate transaction_id rows in sales: {dup_sales}\")\n",
    "else:\n",
    "    print(\"transaction_id not found in sales columns.\")\n",
    "\n",
    "# Shop duplicates by hour_of_day\n",
    "if \"hour_of_day\" in shop.columns:\n",
    "    dup_shop_hour = shop.duplicated(subset=[\"hour_of_day\"]).sum()\n",
    "    print(f\"Duplicate hour_of_day rows in shop: {dup_shop_hour}\")\n",
    "else:\n",
    "    print(\"hour_of_day not found in shop columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a0c29",
   "metadata": {},
   "source": [
    "## 5. Numeric distributions and potential outliers\n",
    "\n",
    "We look at basic descriptive statistics and simple checks to identify:\n",
    "\n",
    "- Unreasonable values (e.g., non-positive quantities or prices).\n",
    "- Very large values that might represent outliers or data entry errors.\n",
    "\n",
    "For this project, we at least:\n",
    "\n",
    "- Confirm that `transaction_qty` and `unit_price` are positive.\n",
    "- Confirm that `hour_of_day` is between 0 and 23.\n",
    "- Confirm that `money` has reasonable ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249cbbf7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "numeric_cols_sales = [\"transaction_qty\", \"unit_price\"]\n",
    "numeric_cols_sales = [c for c in numeric_cols_sales if c in sales.columns]\n",
    "\n",
    "print(\"Sales numeric summary:\")\n",
    "sales[numeric_cols_sales].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4caa0a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "numeric_cols_shop = []\n",
    "for candidate in [\"hour_of_day\", \"money\"]:\n",
    "    if candidate in shop.columns:\n",
    "        numeric_cols_shop.append(candidate)\n",
    "\n",
    "print(\"Shop numeric summary:\")\n",
    "shop[numeric_cols_shop].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c31a14",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check for non-positive qty/price in sales\n",
    "if {\"transaction_qty\", \"unit_price\"}.issubset(sales.columns):\n",
    "    invalid_qty = (sales[\"transaction_qty\"] <= 0).sum()\n",
    "    invalid_price = (sales[\"unit_price\"] <= 0).sum()\n",
    "    print(f\"Non-positive transaction_qty rows: {invalid_qty}\")\n",
    "    print(f\"Non-positive unit_price rows: {invalid_price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dada5b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check hour_of_day range in shop\n",
    "if \"hour_of_day\" in shop.columns:\n",
    "    bad_hours = shop[\n",
    "        (shop[\"hour_of_day\"] < 0) | (shop[\"hour_of_day\"] > 23)\n",
    "    ]\n",
    "    print(f\"Rows with invalid hour_of_day: {len(bad_hours)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85649288",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Basic check for negative money values\n",
    "if \"money\" in shop.columns:\n",
    "    negative_money = (shop[\"money\"] < 0).sum()\n",
    "    print(f\"Rows with negative money: {negative_money}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74aa94e",
   "metadata": {},
   "source": [
    "## 6. Categorical summaries\n",
    "\n",
    "We also examine categorical distributions to understand the structure\n",
    "of the data and potentially detect unexpected categories.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- `store_location`\n",
    "- `product_category`\n",
    "- `Time_of_Day`\n",
    "- `Weekday`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f277028",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if \"store_location\" in sales.columns:\n",
    "    print(\"Top store_location values:\")\n",
    "    print(sales[\"store_location\"].value_counts().head(), \"\\n\")\n",
    "\n",
    "if \"product_category\" in sales.columns:\n",
    "    print(\"Top product_category values:\")\n",
    "    print(sales[\"product_category\"].value_counts().head(), \"\\n\")\n",
    "\n",
    "if \"Time_of_Day\" in shop.columns:\n",
    "    print(\"Time_of_Day distribution:\")\n",
    "    print(shop[\"Time_of_Day\"].value_counts(), \"\\n\")\n",
    "\n",
    "if \"Weekday\" in shop.columns:\n",
    "    print(\"Weekday distribution:\")\n",
    "    print(shop[\"Weekday\"].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ecbae",
   "metadata": {},
   "source": [
    "## 7. Summary of data quality and cleaning decisions\n",
    "\n",
    "Based on the script (`scripts/clean_data.py`) and the checks in this\n",
    "notebook, the following key cleaning steps are applied:\n",
    "\n",
    "### Sales data (`coffee_sales_clean.csv`)\n",
    "\n",
    "- **Whitespace trimming**: All string columns are stripped of leading/trailing whitespace.\n",
    "- **Duplicate removal**: Rows with duplicate `transaction_id` values are dropped.\n",
    "- **Type conversion**:\n",
    "  - `transaction_qty` and `unit_price` are converted to numeric types.\n",
    "- **Invalid values**:\n",
    "  - Rows with missing or non-positive `transaction_qty` or `unit_price`\n",
    "    are removed, since they prevent meaningful revenue calculation.\n",
    "- **Result**:\n",
    "  - A cleaned sales table where each transaction has a unique ID and\n",
    "    valid quantity/price values suitable for aggregation.\n",
    "\n",
    "### Shop data (`coffee_shop_clean.csv`)\n",
    "\n",
    "- **Whitespace trimming**: All string columns are stripped of leading/trailing whitespace.\n",
    "- **Type conversion**:\n",
    "  - `hour_of_day` and `money` are converted to numeric types.\n",
    "- **Range checks**:\n",
    "  - Rows with `hour_of_day` outside the range 0–23 are dropped.\n",
    "  - Rows with missing `money` are dropped (to allow average money per hour).\n",
    "- **Result**:\n",
    "  - A cleaned shop table with valid hourly information that can be used\n",
    "    to build the time-of-day profile in the integration step.\n",
    "\n",
    "These decisions are documented here and referenced in the main project\n",
    "`README.md` under the **Data quality** and **Data cleaning** sections."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs307",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
